# -*-coding:utf-8-*-
# @Time:   2020/9/21 17:19
# @Author: FC
# @Email:  18817289038@163.com

import pandas as pd
import numpy as np
import statsmodels.api as sm
import time
from typing import Any
from scipy.optimize import minimize
import eventlet
from functools import reduce
import warnings
import types
import collections
from statsmodels.tsa.arima_model import ARMA

from SecuritySelect.Optimization import MaxOptModel
from SecuritySelect.FactorProcess.FactorProcess import FactorProcess
from SecuritySelect.constant import (
    KeyName as KN,
    SpecialName as SN,
    PriceVolumeName as PVN,
    timer
)
warnings.filterwarnings('ignore')
# eventlet.monkey_patch()


class ReturnModel(object):
    def __init__(self):
        pass

        # å› å­æ”¶ç›Šå’Œ
        pass

    # ç­‰æƒ
    def equal_weight(self,
                     data: pd.DataFrame,
                     rolling: int = 20,
                     **kwargs):
        """
        å› å­æ”¶ç›Šé¢„æµ‹--ç­‰æƒæ³•ï¼šè¿‡åŽ»ä¸€æ®µæ—¶é—´æ”¶ç›Šçš„ç­‰æƒå¹³å‡ä½œä¸ºä¸‹ä¸€æœŸå› å­æ”¶ç›Šçš„é¢„æµ‹
        :param data: å› å­æ”¶ç›Šåºåˆ—
        :param rolling: æ»šåŠ¨å‘¨æœŸ
        :return:
        """
        fore_ret = data.rolling(rolling).mean().dropna()
        return fore_ret

    # æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡æ³•
    def EWMA(self,
             data: pd.DataFrame,
             alpha: float = 0.5,
             **kwargs):
        """
        pd.ewmä¸­comä¸Žalphaçš„å…³ç³»ä¸º 1 / alpha - 1 = com
        pd.ewmä¸­adjustå‚æ•°éœ€è¦è®¾ç½®ä¸ºFalse
        :param data:
        :param alpha: å½“æœŸæƒé‡ï¼Œå‰ä¸€æœŸæƒé‡ä¸º1-alpha
        :return:
        """
        fore_ret = data.ewm(com=1 / alpha - 1, adjust=False).mean()
        return fore_ret

    # æ—¶é—´åºåˆ—æ¨¡åž‹
    def Time_series(self,
                    data: pd.DataFrame,
                    rolling: int = 20,
                    AR_q: int = 1,
                    MA_p: int = 1,
                    **kwargs):
        fore_ret = data.rolling(rolling).apply(lambda x: self._ARMA(x, AR_q, MA_p))
        return fore_ret

    # TODO å¾…ç ”ç©¶
    def _ARMA(self, data: pd.Series, AR_q: int = 1, MA_p: int = 1):
        try:
            ar_ma = ARMA(data, order=(AR_q, MA_p)).fit(disp=0)
        except Exception as e:
            print(e)
            print("å°è¯•é‡‡ç”¨å…¶ä»–æ»žåŽé˜¶æ•°")
            forecast = np.nan
        else:
            forecast = ar_ma.predict()[-1]

        return forecast

    def KML(self, data: pd.DataFrame):
        pass


class RiskModel(object):

    def __init__(self):
        pass

    # å› å­åæ–¹å·®çŸ©é˜µä¼°è®¡
    def forecast_cov_fact(self,
                          fact_ret: pd.DataFrame,
                          decay: int = 2,
                          order: int = 2,
                          annual: int = 1):
        """

        :param fact_ret: å› å­æ”¶ç›Šåºåˆ—
        :param decay: æŒ‡æ•°åŠ æƒè¡°å‡ç³»æ•°
        :param order: è‡ªç›¸å…³ä¹‹åŽé˜¶æ•°
        :param annual: "å¹´åŒ–"å‚æ•°
        :return:
        """
        # æŒ‡æ•°åŠ æƒåæ–¹å·®çŸ©é˜µ
        F_Raw = self.exp_weight_cov(fact_ret, decay=decay)

        #  Newey-West adjustment
        matrix_orders = np.zeros(shape=(fact_ret.shape[1], fact_ret.shape[1]))
        for order_ in range(1, order + 1):
            w = 1 - order_ / (order + 1)
            # æ»žåŽorderé˜¶çš„è‡ªç›¸å…³åæ–¹å·®çŸ©é˜µ
            matrix_order = self.auto_cor_cov(fact_ret, order=order, decay=decay)
            matrix_orders += w * (matrix_order + matrix_order.T)

        #  Eigenvalue adjustment
        F_NW = annual * (F_Raw + matrix_orders)

        # ç‰¹å¾å€¼è°ƒæ•´
        F_Eigen = self.eigenvalue_adj(F_NW, period=120, M=100)

        # Volatility bias adjustment  TODO
        # F = self.vol_bias_adj(F_Eigen)
        F = F_Eigen
        return F

    # ç‰¹å¼‚æ€§æ”¶ç›Šåæ–¹å·®çŸ©é˜µé¢„æµ‹
    def forecast_cov_spec(self,
                          spec_ret: pd.DataFrame,
                          fact_exp: pd.DataFrame,
                          liq_mv: pd.DataFrame,
                          liq_mv_name: str = PVN.LIQ_MV.value,
                          decay: int = 2,
                          order: int = 5,
                          annual: int = 1):
        """

        :param spec_ret: ä¸ªè‚¡ç‰¹å¼‚æ€§æ”¶ç›Š
        :param fact_exp: å› å­æš´éœ²
        :param liq_mv: æµé€šå¸‚å€¼
        :param liq_mv_name: æµé€šå¸‚å€¼åç§°
        :param decay: æŒ‡æ•°åŠ æƒè¡°å‡å‘¨æœŸ
        :param order: Newey-Westè°ƒæ•´æœ€å¤§æ»žåŽé˜¶æ•°
        :param annual: è°ƒä»“æœŸï¼šå¯¹åæ–¹å·®çŸ©é˜µè¿›è¡Œ"å¹´åŒ–"è°ƒæ•´
        :return:
        """
        # åˆ é™¤æ— æ•ˆèµ„äº§
        eff_asset = spec_ret.iloc[-1, :].dropna().index
        spec_ret_eff = spec_ret[eff_asset]

        # Calculate the weighted covariance of the specific return index
        F_Raw = self.exp_weight_cov(spec_ret_eff, decay=decay)

        #  Newey-West adjustment: è‡ªç”±åº¦è®¾ä¸ºn-1
        matrix_orders = np.zeros(shape=(spec_ret_eff.shape[1], spec_ret_eff.shape[1]))
        for order_ in range(1, order + 1):
            w = 1 - order_ / (order + 1)
            matrix_order = self.auto_cor_cov(spec_ret_eff, order=order_, decay=decay)
            matrix_orders += w * (matrix_order + matrix_order.T)

        #  Eigenvalue adjustment
        F_NW = annual * (F_Raw + matrix_orders)

        #  Structural adjustment
        F_STR = self.structural_adj(F_NW, spec_ret_eff, fact_exp, liq_mv.iloc[:, 0], liq_mv_name)

        # Bayesian compression adjustment
        F_SH = self.Bayesian_compression(F_STR, liq_mv.iloc[:, 0], liq_mv_name)

        # æ³¢åŠ¨çŽ‡åè¯¯è°ƒæ•´  TODO

        # éžå¯¹è§’çŸ©é˜µæ›¿æ¢ä¸º0

        return F_SH

    # æŒ‡æ•°åŠ æƒåæ–¹å·®çŸ©é˜µè®¡ç®—
    def exp_weight_cov(self,
                       data: pd.DataFrame,
                       decay: int = 2) -> pd.DataFrame:
        # Exponentially weighted index volatility: Half-Life attenuation

        w_list = Half_time(period=data.shape[0], decay=decay)
        w_list = sorted(w_list, reverse=False)  # å‡åºæŽ’åˆ—

        cov_w = pd.DataFrame(np.cov(data.T, aweights=w_list), index=data.columns, columns=data.columns)

        return cov_w

    # è‡ªç›¸å…³åæ–¹å·®çŸ©é˜µ
    def auto_cor_cov(self,
                     data: pd.DataFrame,
                     order: int = 2,
                     decay: int = 2) -> pd.DataFrame:
        """
        çŸ©é˜µä¸ŽçŸ©é˜µç›¸å…³æ€§è®¡ç®—ï¼š
        A = np.array([[a11,a21],[a12,a22]])
        B = np.array([[b11,b21],[b12,b22]])

        matrix = [[cov([a11,a21], [a11,a21]), cov([a11,a21], [a12,a22]), cov([a11,a21], [b11,b21]), cov([a11,a21], [b12,b22])],
                  [cov([a12,a22], [a11,a21]), cov([a12,a22], [a12,a22]), cov([a12,a22], [b11,b21]), cov([a12,a22], [b12,b22])],
                  [cov([b11,b21], [a11,a21]), cov([b11,b21], [a12,a22]), cov([b11,b21], [b11,b21]), cov([b11,b21], [b12,b22])],
                  [cov([b12,b22], [a11,a21]), cov([b12,b22], [a12,a22]), cov([b12,b22], [b11,b21]), cov([b12,b22], [b12,b22])]]

        è‡ªç›¸å…³åæ–¹å·®çŸ©é˜µä¸º:
        matrix_at_cor_cov = [[cov([a11,a21], [b11,b21]), cov([a11,a21], [b12,b22])],
                             [cov([a12,a22], [b11,b21]), cov([a12,a22], [b12,b22])]

        æ³¨ï¼š
        è¾“å…¥pd.DataFrameæ ¼å¼çš„æ•°æ®è®¡ç®—åæ–¹å·®ä¼šä»¥è¡Œä¸ºå•ä½å‘é‡è¿›è¡Œè®¡ç®—
        è®¡ç®—å‡ºæ¥çš„åæ–¹å·®çŸ©é˜µä¸­å³ä¸Šè§’order*orderçŸ©é˜µæ‰æ˜¯è‡ªç›¸å…³çŸ©é˜µ
        åæ–¹å·®çŸ©é˜µï¼šæ¨ªå‘ä¸ºå½“æœŸä¸Žå„å› å­æ»žåŽé˜¶æ•°çš„åæ–¹å·®ï¼›çºµå‘ä¸ºæ»žåŽé˜¶æ•°ä¸Žå½“æœŸå„å› å­çš„åæ–¹å·®
        :param data:
        :param order:
        :param decay:
        :return:
        """

        # order matrix
        matrix_order = data.shift(order).dropna(axis=0, how='all')
        matrix = data.iloc[order:, :].copy(deep=True)

        w_list = Half_time(period=matrix.shape[0], decay=decay)
        w_list = sorted(w_list, reverse=False)  # å‡åºæŽ’åˆ—

        covs = np.cov(matrix.T, matrix_order.T, aweights=w_list)  # éœ€è¦å†æµ‹è¯•
        cov_order = pd.DataFrame(covs[: -matrix.shape[1], -matrix.shape[1]:],
                                 index=matrix.columns,
                                 columns=matrix.columns)

        return cov_order

    # ç‰¹å¾å€¼è°ƒæ•´
    def eigenvalue_adj(self,
                       data: np.array,
                       period: int = 120,
                       M: int = 3000,
                       alpha: float = 1.5):
        """

        :param data:Newey-Westè°ƒæ•´åŽçš„åæ–¹å·®çŸ©é˜µ
        :param period: è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿæ”¶ç›ŠæœŸæ•°
        :param M: è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿæ¬¡æ•°
        :param alpha:
        :return:
        """

        # çŸ©é˜µå¥‡å¼‚å€¼åˆ†è§£
        e_vals, U0 = np.linalg.eig(data)

        # å¯¹è§’çŸ©é˜µ
        D0 = np.diag(e_vals)

        # è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ
        eigenvalue_bias = []
        for i in range(M):
            S = np.random.randn(len(e_vals), period)  # æ¨¡æ‹Ÿçš„ç‰¹å¾ç»„åˆæ”¶ç›ŠçŽ‡çŸ©é˜µ, æ”¶ç›ŠæœŸæ•°æ€Žä¹ˆå®š TODO
            f = np.dot(U0, S)  # æ¨¡æ‹Ÿçš„æ”¶ç›ŠçŽ‡çŸ©é˜µ
            F = np.cov(f)  # æ¨¡æ‹Ÿçš„æ”¶ç›ŠçŽ‡åæ–¹å·®çŸ©é˜µ
            e_vas_S, U1 = np.linalg.eig(F)  # å¯¹æ¨¡æ‹Ÿçš„åæ–¹å·®çŸ©é˜µè¿›è¡Œå¥‡å¼‚å€¼åˆ†è§£
            D1 = np.diag(e_vas_S)  # ç”Ÿæˆæ¨¡æ‹Ÿåæ–¹å·®çŸ©é˜µç‰¹å¾å€¼çš„å¯¹è§’çŸ©é˜µ
            D1_real = np.dot(np.dot(U1.T, data), U1)

            D1_real = np.diag(np.diag(D1_real))  # è½¬åŒ–ä¸ºå¯¹è§’çŸ©é˜µ

            lam = D1_real / D1  # ç‰¹å¾å€¼åè¯¯
            eigenvalue_bias.append(lam)

        gam_ = reduce(lambda x, y: x + y, eigenvalue_bias)
        gam = (np.sqrt(gam_ / M) - 1) * alpha + 1
        gam[np.isnan(gam)] = 0

        F_Eigen = pd.DataFrame(np.dot(np.dot(U0, np.dot(gam ** 2, D0)), np.linalg.inv(U0)),
                               index=data.columns,
                               columns=data.columns)

        return F_Eigen

    # ç»“æž„åŒ–è°ƒæ•´
    def structural_adj(self,
                       cov: pd.DataFrame,
                       spec_ret: pd.DataFrame,
                       fact_exp: pd.DataFrame,
                       liq_mv: pd.DataFrame,
                       liq_mv_name: PVN.LIQ_MV.value,
                       time_window: int = 120):
        """

        :param cov: ç»Newey-Westè°ƒæ•´çš„ä¸ªè‚¡ç‰¹å¼‚æ”¶ç›ŠçŸ©é˜µ
        :param spec_ret: ä¸ªè‚¡ç‰¹å¼‚æ”¶ç›Šåºåˆ—
        :param fact_exp: å› å­æš´éœ²
        :param liq_mv: æµé€šå¸‚å€¼
        :param liq_mv_name: æµé€šå¸‚å€¼åç§°
        :param time_window: ä¸ªè‚¡ç‰¹å¼‚æ”¶ç›Šçš„æ—¶é—´çª—å£ï¼ˆåŽé¢è€ƒè™‘æ”¹ä¸ºç‰¹å¼‚æ”¶ç›Šåºåˆ—çš„é•¿åº¦ï¼‰
        :return:
        """
        # è®¡ç®—åè°ƒå‚æ•°
        h_n = spec_ret.count()  # éžç©ºæ•°é‡
        V_n = (h_n - 20 / 4) / 20 * 2  # æ•°æ®ç¼ºå¤±ç¨‹åº¦ï¼ˆå…ˆç”¨20æµ‹è¯•ï¼‰

        sigma_n = spec_ret.std().fillna(1)  # æ ·æœ¬ç­‰æƒæ ‡å‡†å·®ï¼ˆæ— æ³•è®¡ç®—çš„æ ‡å‡†å·®è®°ä¸º1ï¼‰  TODO

        sigma_n_steady = (spec_ret.quantile(.75) - spec_ret.quantile(0.25)) / 1.35  # æ ·æœ¬ç¨³å¥ä¼°è®¡æ ‡å‡†å·®

        Z_n = abs((sigma_n - sigma_n_steady) / sigma_n_steady)  # æ•°æ®è‚¥å°¾ç¨‹åº¦

        # å°†æ— é™å¤§å€¼æ›¿æ¢ä¸º0
        Z_n[np.isinf(Z_n)] = 0
        Z_n.fillna(0, inplace=True)

        left_, right_ = V_n.where(V_n > 0, 0), np.exp(1 - Z_n)

        left_, right_ = left_.where(left_ < 1, 1), right_.where(right_ < 1, 1)
        gam_n = left_ * right_  # ä¸ªè‚¡åè°ƒå‚æ•°[0,1]

        reg_data = pd.concat([np.log(sigma_n), liq_mv, gam_n, fact_exp], axis=1)
        reg_data.columns = ['sigma', liq_mv_name, 'gam_n'] + fact_exp.columns.tolist()

        ref_data_com = reg_data[reg_data['gam_n'] == 1]

        # åŠ æƒï¼ˆæµé€šå¸‚å€¼ï¼‰æœ€å°äºŒä¹˜æ³•ç”¨ä¼˜è´¨è‚¡ç¥¨ä¼°è®¡å› å­å¯¹ç‰¹å¼‚æ³¢åŠ¨çš„è´¡çŒ®å€¼
        model = sm.WLS(ref_data_com['sigma'], ref_data_com[fact_exp.columns], weights=ref_data_com['gam_n']).fit()

        # ä¸ªè‚¡ç»“æž„åŒ–ç‰¹å¼‚æ³¢åŠ¨é¢„æµ‹å€¼
        sigma_STR = pd.DataFrame(np.diag(np.exp(np.dot(fact_exp, model.params)) * 1.05),
                                 index=fact_exp.index,
                                 columns=fact_exp.index)

        # å¯¹ç‰¹å¼‚æ”¶ç›ŠçŸ©é˜µè¿›è¡Œç»“æž„åŒ–è°ƒæ•´
        F_STR = sigma_STR.mul((1 - gam_n), axis=0) + cov.mul(gam_n, axis=0)

        return F_STR

    # è´å¶æ–¯åŽ‹ç¼©
    def Bayesian_compression(self,
                             cov: pd.DataFrame,
                             liq_mv: pd.DataFrame,
                             liq_mv_name: PVN.LIQ_MV.value,
                             group_num: int = 10,
                             q: int = 1
                             ):
        """
        ðœŽ_ð‘›_ð‘†ð» = ð‘£_ð‘›*ðœŽ_ð‘› + (1 âˆ’ ð‘£_ð‘›)*ðœŽ_ð‘›^

        :param cov: ç»ç»“æž„åŒ–è°ƒæ•´çš„ç‰¹å¼‚æ”¶ç›ŠçŸ©é˜µ
        :param liq_mv: æµé€šå¸‚å€¼
        :param liq_mv_name: æµé€šå¸‚å€¼åç§°
        :param group_num: åˆ†ç»„ä¸ªæ•°
        :param q: åŽ‹ç¼©ç³»æ•°ï¼Œè¯¥ç³»æ•°è¶Šå¤§ï¼Œå…ˆéªŒé£Žé™©çŸ©é˜µæ‰€å æƒé‡è¶Šå¤§
        :return:
        """
        df_ = pd.DataFrame({"sigma_n": np.diag(cov), liq_mv_name: liq_mv})
        # æŒ‰æµé€šå¸‚å€¼åˆ†ç»„
        df_['Group'] = pd.cut(df_['sigma_n'], group_num, labels=[f'Group_{i}' for i in range(1, group_num + 1)])

        # å„ç»„ç‰¹å¼‚é£Žé™©å¸‚å€¼åŠ æƒå‡å€¼
        df_['weight'] = df_.groupby('Group', group_keys=False).apply(lambda x: x[liq_mv_name] / x[liq_mv_name].sum())
        sigma_n_weight = df_.groupby('Group').apply(lambda x: x['weight'] @ x['sigma_n'])
        sigma_n_weight.name = 'sigma_n_weight'

        df_N1 = pd.merge(df_, sigma_n_weight, left_on=['Group'], right_index=True, how='left')

        # ä¸ªè‚¡æ‰€å±žåˆ†ç»„ç‰¹å¼‚æ³¢åŠ¨çš„æ ‡å‡†å·®

        try:
            delta_n = df_N1.groupby('Group').apply(
                    lambda x: np.nan if x.empty else pow(sum((x['sigma_n'] - x['sigma_n_weight']) ** 2) / x.shape[0], 0.5))
        except Exception as e:
            delta_n = df_N1.groupby('Group').apply(
                lambda x: np.nan if x.empty else pow(sum((x['sigma_n'] - x['sigma_n_weight']) ** 2) / x.shape[0], 0.5))
            print(e)

        delta_n.name = 'delta'

        df_N2 = pd.merge(df_N1, delta_n, left_on=['Group'], right_index=True, how='left')

        # åŽ‹ç¼©ç³»æ•°
        df_N2['V_n'] = q * abs(df_N2['sigma_n'] - df_N2['sigma_n_weight']) / \
                       (df_N2['delta'] + q * abs(df_N2['sigma_n'] - df_N2['sigma_n_weight']))

        # è°ƒæ•´åŽçš„ç‰¹å¼‚æ³¢åŠ¨
        sigma_SH = df_N2['V_n'] * df_N2['sigma_n_weight'] + (1 - df_N2['V_n']) * df_N2['sigma_n']
        F_SH = pd.DataFrame(np.diag(np.array(sigma_SH)), index=sigma_SH.index, columns=sigma_SH.index)

        return F_SH


class Strategy(object):
    """
    ä¼˜åŒ–æ¨¡åž‹è¾“å…¥æ•°æ®å­˜æ”¾æ ¼å¼ä¸ºå­—å…¸å½¢å¼ï¼š{"time": values}
    é™¤å› å­åç§°å¤–ï¼Œå…¶ä»–è¾“å…¥å‚æ•°çš„åç§°åŒä¸€ä¸ºç³»ç»Ÿå®šä¹‰çš„åç§°ï¼Œè¯¥åç§°å®šåœ¨constantè„šæœ¬ä¸‹
    """

    # TODO ä¼˜åŒ–ï¼Œè€ƒè™‘ä¼˜åŒ–ä¸ºé™æ€ç±»
    class OPT(MaxOptModel):

        """
        é»˜è®¤:
        1.ç›®æ ‡å‡½æ•°ä¸ºæœ€å¤§åŒ–æ”¶ç›Šæ¯”ä¸Šæ³¢åŠ¨
        2.æƒé‡ä»‹äºŽ0åˆ°1ä¹‹é—´
        3.æƒé‡å’Œä¸º1
        4.æœ€å¤§è¿­ä»£æ¬¡æ•°ä¸º300
        5.å®¹å¿åº¦ä¸º1e-7
        """

        def __init__(self, data: pd.DataFrame, n: int):
            super().__init__(data, n)

        # ç›®æ ‡å‡½æ•°
        def object_func(self, w):
            """
            ç›®æ ‡å‡½æ•°é»˜è®¤ä¸ºå¤æ™®æ¯”æœ€å¤§åŒ–æ¨¡åž‹ï¼Œé€šè¿‡å‰é¢åŠ ä¸Šè´Ÿå·è½¬åŒ–ä¸ºæœ€å°åŒ–æ¨¡åž‹
            :param w:
            :return:
            """
            mean = np.array(self.data.mean())
            cov = np.array(self.data.cov())  # åæ–¹å·®
            func = - np.dot(w, mean) / np.sqrt(np.dot(w, np.dot(w, cov)))
            return func

        # çº¦æŸæ¡ä»¶
        def _constraint1(self, w, **kwargs):
            return sum(w) - 1

        # çº¦æŸæ¡ä»¶å‡½æ•°é›†
        def _constraints(self, **kwargs):
            limit = {'type': 'eq', 'fun': self._constraint1}
            return limit

    def __init__(self,
                 fac_exp: pd.DataFrame,
                 stock_ret: pd.Series,
                 ind_exp: pd.Series,
                 liq_mv: pd.Series,
                 stock_weight_up: pd.DataFrame = None,
                 stock_weight_down: pd.DataFrame = None,
                 ind_weight: pd.DataFrame = None,
                 fact_weight: pd.DataFrame = None,
                 holding_period: int = 1):

        self.RET = ReturnModel()
        self.RISK = RiskModel()
        self.FP = FactorProcess()

        self.fac_exp = fac_exp  # å› å­æš´éœ²
        self.stock_ret = stock_ret  # è‚¡ç¥¨æ”¶ç›Šæ ‡ç­¾
        self.ind_exp = ind_exp  # è¡Œä¸šæ ‡ç­¾
        self.liq_mv = liq_mv  # æµé€šå¸‚å€¼
        self.hp = holding_period

        self.stock_weight_up = stock_weight_up  # ä¸ªè‚¡æƒé‡çº¦æŸä¸Šé™
        self.stock_weight_down = stock_weight_down  # ä¸ªè‚¡æƒé‡çº¦æŸä¸‹é™
        self.ind_weight = ind_weight  # è¡Œä¸šæƒé‡çº¦æŸ
        self.fact_weight = fact_weight  # å› å­æš´éœ²çº¦æŸ

        self.limit = []  # çº¦æŸæ¡ä»¶
        self.bonds = []  # æƒé‡çº¦æŸæ¡ä»¶
        self.const = []  # çº¦æŸå­æ¡ä»¶

        self.fact_name = self.fac_exp.columns  # å› å­åç§°

        # self.holding_ret = self._holding_return(stock_ret, holding_period)  # æŒæœ‰æœŸæ”¶ç›Š
        self.holding_ret = stock_ret
        self.df_input = {}

        self.OPT_params = collections.defaultdict(dict)

    # å› å­æ”¶ç›Šå’Œæ®‹å·®æ”¶ç›Š
    @timer
    def fact_residual_ret(self):

        data_input = pd.concat([self.stock_ret, self.ind_exp, self.fac_exp, self.liq_mv], axis=1, join='inner')
        reg_res = data_input.groupby(KN.TRADE_DATE.value).apply(self.WLS)

        fact_return = pd.DataFrame(map(lambda x: x.params[self.fact_name], reg_res), index=reg_res.index)
        specific_return = pd.concat(map(lambda x: x.resid, reg_res)).unstack()

        self.df_input['FACT_RET'] = fact_return
        self.df_input['SPEC_RET'] = specific_return

    # æ”¶ç›Šé¢„æµ‹1
    @timer
    def Return_Forecast1(self, **kwargs):
        """
        å½“æœŸå› å­æš´éœ²ä¸Žä¸‹æœŸä¸ªè‚¡æ”¶ç›Šæµé€šå¸‚å€¼åŠ æƒæœ€å°äºŒä¹˜æ³•å›žå½’å¾—åˆ°ä¸‹æœŸå› å­æ”¶ç›Šé¢„æµ‹å€¼
        ä¸‹æœŸå› å­æ”¶ç›Šé¢„æµ‹å€¼ä¸Žä¸‹æœŸå› å­æš´éœ²ç›¸ä¹˜å¾—åˆ°å› å­æ”¶ç›Šä½œä¸ºå½“å¤©å¯¹ä¸‹æœŸçš„é¢„æµ‹å€¼
        :return:
        """

        data_input = pd.concat([self.holding_ret, self.ind_exp, self.fac_exp, self.liq_mv], axis=1, join='inner')

        # å› å­æ”¶ç›Šé¢„æµ‹
        reg_res = data_input.groupby(KN.TRADE_DATE.value).apply(self.WLS)

        fact_ret_fore_ = pd.DataFrame(map(lambda x: x.params[self.fact_name], reg_res),
                                      index=reg_res.index)  # å› å­æ”¶ç›Šé¢„æµ‹å€¼

        fact_ret_fore = fact_ret_fore_.shift(self.hp)
        # ä¸ªè‚¡æ”¶ç›Šé¢„æµ‹
        asset_ret_fore = self.fac_exp.groupby(KN.TRADE_DATE.value,
                                              group_keys=False).apply(lambda x: x @ fact_ret_fore.loc[x.index[0][0], :])

        asset_ret_fore.dropna(inplace=True)

        self.OPT_params['ASSET_RET_FORECAST'] = asset_ret_fore.unstack().T.to_dict('series')

    # æ”¶ç›Šé¢„æµ‹2
    @timer
    def Return_Forecast2(self,
                         method: str = 'EWMA',
                         **kwargs):

        # å› å­æ”¶ç›Šé¢„æµ‹
        fact_ret_fore_ = getattr(self.RET, method)(self.df_input['FACT_RET'], **kwargs)

        fact_ret_fore = fact_ret_fore_.shift(self.hp)

        # ä¸ªè‚¡æ”¶ç›Šé¢„æµ‹
        asset_ret_fore = self.fac_exp.groupby(KN.TRADE_DATE.value,
                                              group_keys=False).apply(lambda x: x @ fact_ret_fore.loc[x.index[0][0], :])

        asset_ret_fore.dropna(inplace=True)
        try:
            self.OPT_params['ASSET_RET_FORECAST'] = asset_ret_fore.unstack().T.to_dict('series')
        except Exception as e:
            print(e)

    # é£Žé™©é¢„æµ‹
    @timer
    def Risk_Forecast(self, rolling: int = 20):

        length = self.df_input['FACT_RET'].shape[0]

        for i in range(rolling, length + 1):
            fact_ret_sub = self.df_input['FACT_RET'].iloc[i - rolling: i, :]  # å› å­æ”¶ç›Š
            spec_ret_sub = self.df_input['SPEC_RET'].iloc[i - rolling: i, :]  # ä¸ªè‚¡ç‰¹å¼‚æ”¶ç›Š
            fact_exp = self.fac_exp.xs(fact_ret_sub.index[-1])  # å› å­æš´éœ²

            res_f = self.RISK.forecast_cov_fact(fact_ret_sub, order=2, decay=2)  # å› å­åæ–¹å·®çŸ©é˜µçš„ä¼°è®¡
            res_s = self.RISK.forecast_cov_spec(spec_ret_sub, fact_exp, fact_exp, decay=2, order=5)  # ä¸ªè‚¡ç‰¹å¼‚çŸ©é˜µçš„ä¼°è®¡ TODO test

            self.OPT_params['COV_FACT'][fact_ret_sub.index[-1]] = res_f
            self.OPT_params['COV_SPEC'][fact_ret_sub.index[-1]] = res_s
            self.OPT_params['FACT_EXP'][fact_ret_sub.index[-1]] = fact_exp

    def Weight_OPT(self,
                   method: str = 'MAX_RET',
                   _const: str = '',
                   bounds: str = '01',
                   **kwargs):


        # Set the objective function
        if method == 'MIN_RISK':
            def object_func(self, w):
                cov = self.data_cov  # åæ–¹å·®
                func = np.dot(w, np.dot(w, cov))
                return func

        elif method == 'MAX_RET/RISK':
            def object_func(self, w):
                mean = self.data_mean
                cov = self.data_cov
                func = - np.dot(w, mean) / np.sqrt(np.dot(w, np.dot(w, cov)))
                return func

        elif method == 'MAX_RET':
            def object_func(self, w):
                mean = self.data_mean
                func = - np.dot(w, mean)
                return func
        else:
            print("Please input method!")
            return None

        # opt
        for index_ in self.OPT_params['FACT_EXP'].keys():
            X = self.OPT_params['FACT_EXP'][index_]
            F = self.OPT_params['COV_FACT'][index_]
            D = self.OPT_params['COV_SPEC'][index_]
            R = self.OPT_params['ASSET_RET_FORECAST'][index_].dropna()  # æ”¶ç›Šéœ€è¦å‰”é™¤æ— æ•ˆæ ·æœ¬ä¸Žåæ–¹å·®å¯¹é½

            COV = np.dot(X, np.dot(F, X.T)) + D
            opt = self.OPT(pd.DataFrame(), X.shape[0])

            # Set the constraint
            if 'stock' in _const:
                up = self.stock_weight_down.loc[index_, :].reindex(COV.index)
                down = self.stock_weight_up.loc[index_, :].reindex(COV.index)

                self.bonds = tuple(zip(up, down))
                self.limit.append({'type': 'eq', 'fun': lambda w: sum(w)})

            elif 'ind' in _const:
                pass
            elif 'fact' in _const:
                pass

            else:
                self.bonds = ((0., 1.), ) * COV.shape[0]
                self.limit.append({'type': 'eq', 'fun': lambda w: sum(w) - 1})

            limit = tuple(self.limit)

            def _constraints(self, **kwargs):
                return limit


            opt.data_cov = COV
            opt.data_mean = R

            opt.object_func = types.MethodType(object_func, opt)
            opt.bonds = self.bonds
            opt._constraints = types.MethodType(_constraints, opt)

            # setattr(opt, '_constraints',_constraints)
            # for i in self.const:
            #     setattr(opt, i.__name__, i)

            try:
                sta = time.time()
                res = opt.solve(ftol=1e-8, maxiter=30)
                print(f"è¿­ä»£è€—æ—¶ï¼š{time.time() - sta}")
            except Exception as e:
                print(e)
            self.OPT_params['WEIGHT'][index_] = pd.Series(index=X.index, data=res.x)

    # å‡€å€¼æ›²çº¿
    def Nav(self):
        p = pd.concat(self.OPT_params['WEIGHT'])

        pass

    def WLS(self, data_: pd.DataFrame) -> object or None:
        """è¿”å›žå›žå½’ç±»"""
        # p = data_.dropna()
        if data_.shape[0] < data_.shape[1]:
            res = pd.Series(index=['T', 'factor_return'])
        else:
            X = pd.get_dummies(data_.loc[:, data_.columns.difference([PVN.LIQ_MV.value, PVN.STOCK_RETURN.value])],
                               columns=[SN.INDUSTRY_FLAG.value])

            Y = data_[PVN.STOCK_RETURN.value]

            W = data_[PVN.LIQ_MV.value]

            res = sm.WLS(Y, X, weights=W).fit()  # æµé€šå¸‚å€¼åŠ æƒæœ€å°äºŒä¹˜æ³•
        return res

    def main(self):
        # å› å­é¢„å¤„ç†
        m = self.fac_exp.apply(lambda x: self.FP.main(x, 'before_after_3sigma', '', 'z_score'))


        # å› å­æ”¶ç›Šä¸Žä¸ªè‚¡æ®‹å·®æ”¶ç›Šè®¡ç®—

        self.fact_residual_ret()

        # æ”¶ç›Šé¢„æµ‹
        self.Return_Forecast1(alpha=0.1)

        # é£Žé™©ä¼°è®¡
        self.Risk_Forecast()

        # OPT
        self.Weight_OPT()

        # NAV
        self.Nav()
        pass

    @staticmethod
    def _holding_return(ret: pd.Series,
                        holding_period: int = 1) -> pd.Series:
        """
        è®¡ç®—æŒæœ‰ä¸åŒå‘¨æœŸçš„è‚¡ç¥¨æ”¶ç›ŠçŽ‡
        :param ret: è‚¡ç¥¨æ”¶ç›ŠçŽ‡åºåˆ—
        :param holding_period: æŒæœ‰å‘¨æœŸ
        :return:
        """

        ret_sub = ret.copy(deep=True)

        # Holding period return
        ret_sub = ret_sub.add(1)

        ret_label = 1
        for shift_ in range(holding_period):
            ret_label *= ret_sub.groupby(KN.STOCK_ID.value).shift(- shift_)

        ret_label = ret_label.sub(1)

        return ret_label


# åŠè¡°æƒé‡
def Half_time(period: int, decay: int = 2) -> list:
    weight_list = [pow(2, (i - period - 1) / decay) for i in range(1, period + 1)]

    weight_1 = [i / sum(weight_list) for i in weight_list]

    return weight_1


if __name__ == '__main__':
    data_ = pd.read_csv('C:\\Users\\User\\Desktop\\test\\test.csv')
    # mv = pd.read_csv("A:\\æ•°æ®\\Process\\mv.csv")
    data_ = data_[(data_['date'] > '2014-04-01') & (data_['date'] < '2014-07-01')]
    data_.set_index(['date', 'stock_id'], inplace=True)

    df_ret = data_[PVN.STOCK_RETURN.value]
    df_ind = data_[SN.INDUSTRY_FLAG.value]
    df_fact = data_[['Total', 'Parent']]
    # df_fact_exp = pd.read_csv('A:\\æ•°æ®\\FactorPool\\Factors_Effective\\roa_ttm.csv')

    df_liq_mv = data_[PVN.LIQ_MV.value]
    df_liq_mv.name = PVN.LIQ_MV.value

    # data_ = np.random.rand(200).reshape(50, 4)
    # data_ret = np.random.random(50) / 30
    # data_ind = [1, 2, 3, 4, 5, 6] * 5 + [3, 4, 1, 7] * 5
    # df_ret = pd.Series(data=data_ret, name=PVN.STOCK_RETURN.value)
    # df_ind = pd.Series(data_ind, name=SN.INDUSTRY_FLAG.value)
    # df_fact = pd.DataFrame(data_, columns=[f'fact_{i}' for i in range(0, 4)])

    # è¾“å…¥å˜é‡ï¼šå› å­æš´éœ²ï¼Œä¸ªè‚¡æ”¶ç›Šï¼Œè¡Œä¸šæ ‡è¯†ï¼Œä¸ªè‚¡æµé€šå¸‚å€¼
    A = Strategy(df_fact, df_ret, df_ind, df_liq_mv)
    A.main()
    print("s")
