# -*-coding:utf-8-*-
# @Time:   2020/10/19 20:04
# @Author: FC
# @Email:  18817289038@163.com

import pandas as pd
import numpy as np
import statsmodels.api as sm
from functools import reduce
from constant import (
    PriceVolumeName as PVN,
)


class RiskModel(object):

    def __init__(self):
        pass

    # å› å­åæ–¹å·®çŸ©é˜µä¼°è®¡
    def forecast_cov_fact(self,
                          fact_ret: pd.DataFrame,
                          decay: int = 2,
                          order: int = 2,
                          annual: int = 1):
        """

        :param fact_ret: å› å­æ”¶ç›Šåºåˆ—
        :param decay: æŒ‡æ•°åŠ æƒè¡°å‡ç³»æ•°
        :param order: è‡ªç›¸å…³ä¹‹åŽé˜¶æ•°
        :param annual: "å¹´åŒ–"å‚æ•°
        :return:
        """
        # æŒ‡æ•°åŠ æƒåæ–¹å·®çŸ©é˜µ
        F_Raw = self.exp_weight_cov(fact_ret, decay=decay)

        #  Newey-West adjustment
        matrix_orders = np.zeros(shape=(fact_ret.shape[1], fact_ret.shape[1]))
        for order_ in range(1, order + 1):
            w = 1 - order_ / (order + 1)
            # æ»žåŽorderé˜¶çš„è‡ªç›¸å…³åæ–¹å·®çŸ©é˜µ
            matrix_order = self.auto_cor_cov(fact_ret, order=order, decay=decay)
            matrix_orders += w * (matrix_order + matrix_order.T)

        #  Eigenvalue adjustment
        F_NW = annual * (F_Raw + matrix_orders)

        # ç‰¹å¾å€¼è°ƒæ•´
        F_Eigen = self.eigenvalue_adj(F_NW, period=120, M=100)

        # Volatility bias adjustment  TODO
        # F = self.vol_bias_adj(F_Eigen)
        F = F_Eigen
        return F

    # ç‰¹å¼‚æ€§æ”¶ç›Šåæ–¹å·®çŸ©é˜µé¢„æµ‹
    def forecast_cov_spec(self,
                          spec_ret: pd.DataFrame,
                          fact_exp: pd.DataFrame,
                          liq_mv: pd.DataFrame,
                          liq_mv_name: str = PVN.LIQ_MV.value,
                          decay: int = 2,
                          order: int = 5,
                          annual: int = 1):
        """

        :param spec_ret: ä¸ªè‚¡ç‰¹å¼‚æ€§æ”¶ç›Š
        :param fact_exp: å› å­æš´éœ²
        :param liq_mv: æµé€šå¸‚å€¼
        :param liq_mv_name: æµé€šå¸‚å€¼åç§°
        :param decay: æŒ‡æ•°åŠ æƒè¡°å‡å‘¨æœŸ
        :param order: Newey-Westè°ƒæ•´æœ€å¤§æ»žåŽé˜¶æ•°
        :param annual: è°ƒä»“æœŸï¼šå¯¹åæ–¹å·®çŸ©é˜µè¿›è¡Œ"å¹´åŒ–"è°ƒæ•´
        :return:
        """
        # åˆ é™¤æ— æ•ˆèµ„äº§
        eff_asset = spec_ret.iloc[-1, :].dropna().index
        spec_ret_eff = spec_ret[eff_asset]

        # Calculate the weighted covariance of the specific return index
        F_Raw = self.exp_weight_cov(spec_ret_eff, decay=decay)

        #  Newey-West adjustment: è‡ªç”±åº¦è®¾ä¸ºn-1
        matrix_orders = np.zeros(shape=(spec_ret_eff.shape[1], spec_ret_eff.shape[1]))
        for order_ in range(1, order + 1):
            w = 1 - order_ / (order + 1)
            matrix_order = self.auto_cor_cov(spec_ret_eff, order=order_, decay=decay)
            matrix_orders += w * (matrix_order + matrix_order.T)

        #  Eigenvalue adjustment
        F_NW = annual * (F_Raw + matrix_orders)

        #  Structural adjustment
        F_STR = self.structural_adj(F_NW, spec_ret_eff, fact_exp, liq_mv.iloc[:, 0], liq_mv_name)

        # Bayesian compression adjustment
        F_SH = self.Bayesian_compression(F_STR, liq_mv.iloc[:, 0], liq_mv_name)

        # æ³¢åŠ¨çŽ‡åè¯¯è°ƒæ•´  TODO

        # éžå¯¹è§’çŸ©é˜µæ›¿æ¢ä¸º0

        return F_SH

    # æŒ‡æ•°åŠ æƒåæ–¹å·®çŸ©é˜µè®¡ç®—
    def exp_weight_cov(self,
                       data: pd.DataFrame,
                       decay: int = 2) -> pd.DataFrame:
        # Exponentially weighted index volatility: Half-Life attenuation

        w_list = self.Half_time(period=data.shape[0], decay=decay)
        w_list = sorted(w_list, reverse=False)  # å‡åºæŽ’åˆ—

        cov_w = pd.DataFrame(np.cov(data.T, aweights=w_list), index=data.columns, columns=data.columns)

        return cov_w

    # è‡ªç›¸å…³åæ–¹å·®çŸ©é˜µ
    def auto_cor_cov(self,
                     data: pd.DataFrame,
                     order: int = 2,
                     decay: int = 2) -> pd.DataFrame:
        """
        çŸ©é˜µä¸ŽçŸ©é˜µç›¸å…³æ€§è®¡ç®—ï¼š
        A = np.array([[a11,a21],[a12,a22]])
        B = np.array([[b11,b21],[b12,b22]])

        matrix = [[cov([a11,a21], [a11,a21]), cov([a11,a21], [a12,a22]), cov([a11,a21], [b11,b21]), cov([a11,a21], [b12,b22])],
                  [cov([a12,a22], [a11,a21]), cov([a12,a22], [a12,a22]), cov([a12,a22], [b11,b21]), cov([a12,a22], [b12,b22])],
                  [cov([b11,b21], [a11,a21]), cov([b11,b21], [a12,a22]), cov([b11,b21], [b11,b21]), cov([b11,b21], [b12,b22])],
                  [cov([b12,b22], [a11,a21]), cov([b12,b22], [a12,a22]), cov([b12,b22], [b11,b21]), cov([b12,b22], [b12,b22])]]

        è‡ªç›¸å…³åæ–¹å·®çŸ©é˜µä¸º:
        matrix_at_cor_cov = [[cov([a11,a21], [b11,b21]), cov([a11,a21], [b12,b22])],
                             [cov([a12,a22], [b11,b21]), cov([a12,a22], [b12,b22])]

        æ³¨ï¼š
        è¾“å…¥pd.DataFrameæ ¼å¼çš„æ•°æ®è®¡ç®—åæ–¹å·®ä¼šä»¥è¡Œä¸ºå•ä½å‘é‡è¿›è¡Œè®¡ç®—
        è®¡ç®—å‡ºæ¥çš„åæ–¹å·®çŸ©é˜µä¸­å³ä¸Šè§’order*orderçŸ©é˜µæ‰æ˜¯è‡ªç›¸å…³çŸ©é˜µ
        åæ–¹å·®çŸ©é˜µï¼šæ¨ªå‘ä¸ºå½“æœŸä¸Žå„å› å­æ»žåŽé˜¶æ•°çš„åæ–¹å·®ï¼›çºµå‘ä¸ºæ»žåŽé˜¶æ•°ä¸Žå½“æœŸå„å› å­çš„åæ–¹å·®
        :param data:
        :param order:
        :param decay:
        :return:
        """

        # order matrix
        matrix_order = data.shift(order).dropna(axis=0, how='all')
        matrix = data.iloc[order:, :].copy(deep=True)

        w_list = self.Half_time(period=matrix.shape[0], decay=decay)
        w_list = sorted(w_list, reverse=False)  # å‡åºæŽ’åˆ—

        covs = np.cov(matrix.T, matrix_order.T, aweights=w_list)  # éœ€è¦å†æµ‹è¯•
        cov_order = pd.DataFrame(covs[: -matrix.shape[1], -matrix.shape[1]:],
                                 index=matrix.columns,
                                 columns=matrix.columns)

        return cov_order

    # ç‰¹å¾å€¼è°ƒæ•´
    def eigenvalue_adj(self,
                       data: np.array,
                       period: int = 120,
                       M: int = 3000,
                       alpha: float = 1.5):
        """

        :param data:Newey-Westè°ƒæ•´åŽçš„åæ–¹å·®çŸ©é˜µ
        :param period: è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿæ”¶ç›ŠæœŸæ•°
        :param M: è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿæ¬¡æ•°
        :param alpha:
        :return:
        """

        # çŸ©é˜µå¥‡å¼‚å€¼åˆ†è§£
        e_vals, U0 = np.linalg.eig(data)

        # å¯¹è§’çŸ©é˜µ
        D0 = np.diag(e_vals)

        # è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ
        eigenvalue_bias = []
        for i in range(M):
            S = np.random.randn(len(e_vals), period)  # æ¨¡æ‹Ÿçš„ç‰¹å¾ç»„åˆæ”¶ç›ŠçŽ‡çŸ©é˜µ, æ”¶ç›ŠæœŸæ•°æ€Žä¹ˆå®š TODO
            f = np.dot(U0, S)  # æ¨¡æ‹Ÿçš„æ”¶ç›ŠçŽ‡çŸ©é˜µ
            F = np.cov(f)  # æ¨¡æ‹Ÿçš„æ”¶ç›ŠçŽ‡åæ–¹å·®çŸ©é˜µ
            e_vas_S, U1 = np.linalg.eig(F)  # å¯¹æ¨¡æ‹Ÿçš„åæ–¹å·®çŸ©é˜µè¿›è¡Œå¥‡å¼‚å€¼åˆ†è§£
            D1 = np.diag(e_vas_S)  # ç”Ÿæˆæ¨¡æ‹Ÿåæ–¹å·®çŸ©é˜µç‰¹å¾å€¼çš„å¯¹è§’çŸ©é˜µ
            D1_real = np.dot(np.dot(U1.T, data), U1)

            D1_real = np.diag(np.diag(D1_real))  # è½¬åŒ–ä¸ºå¯¹è§’çŸ©é˜µ

            lam = D1_real / D1  # ç‰¹å¾å€¼åè¯¯
            eigenvalue_bias.append(lam)

        gam_ = reduce(lambda x, y: x + y, eigenvalue_bias)
        gam = (np.sqrt(gam_ / M) - 1) * alpha + 1
        gam[np.isnan(gam)] = 0

        F_Eigen = pd.DataFrame(np.dot(np.dot(U0, np.dot(gam ** 2, D0)), np.linalg.inv(U0)),
                               index=data.columns,
                               columns=data.columns)

        return F_Eigen

    # ç»“æž„åŒ–è°ƒæ•´
    def structural_adj(self,
                       cov: pd.DataFrame,
                       spec_ret: pd.DataFrame,
                       fact_exp: pd.DataFrame,
                       liq_mv: pd.DataFrame,
                       liq_mv_name: PVN.LIQ_MV.value,
                       time_window: int = 120):
        """

        :param cov: ç»Newey-Westè°ƒæ•´çš„ä¸ªè‚¡ç‰¹å¼‚æ”¶ç›ŠçŸ©é˜µ
        :param spec_ret: ä¸ªè‚¡ç‰¹å¼‚æ”¶ç›Šåºåˆ—
        :param fact_exp: å› å­æš´éœ²
        :param liq_mv: æµé€šå¸‚å€¼
        :param liq_mv_name: æµé€šå¸‚å€¼åç§°
        :param time_window: ä¸ªè‚¡ç‰¹å¼‚æ”¶ç›Šçš„æ—¶é—´çª—å£ï¼ˆåŽé¢è€ƒè™‘æ”¹ä¸ºç‰¹å¼‚æ”¶ç›Šåºåˆ—çš„é•¿åº¦ï¼‰
        :return:
        """
        # è®¡ç®—åè°ƒå‚æ•°
        h_n = spec_ret.count()  # éžç©ºæ•°é‡
        V_n = (h_n - 20 / 4) / 20 * 2  # æ•°æ®ç¼ºå¤±ç¨‹åº¦ï¼ˆå…ˆç”¨20æµ‹è¯•ï¼‰

        sigma_n = spec_ret.std().fillna(1)  # æ ·æœ¬ç­‰æƒæ ‡å‡†å·®ï¼ˆæ— æ³•è®¡ç®—çš„æ ‡å‡†å·®è®°ä¸º1ï¼‰  TODO

        sigma_n_steady = (spec_ret.quantile(.75) - spec_ret.quantile(0.25)) / 1.35  # æ ·æœ¬ç¨³å¥ä¼°è®¡æ ‡å‡†å·®

        Z_n = abs((sigma_n - sigma_n_steady) / sigma_n_steady)  # æ•°æ®è‚¥å°¾ç¨‹åº¦

        # å°†æ— é™å¤§å€¼æ›¿æ¢ä¸º0
        Z_n[np.isinf(Z_n)] = 0
        Z_n.fillna(0, inplace=True)

        left_, right_ = V_n.where(V_n > 0, 0), np.exp(1 - Z_n)

        left_, right_ = left_.where(left_ < 1, 1), right_.where(right_ < 1, 1)
        gam_n = left_ * right_  # ä¸ªè‚¡åè°ƒå‚æ•°[0,1]

        reg_data = pd.concat([np.log(sigma_n), liq_mv, gam_n, fact_exp], axis=1)
        reg_data.columns = ['sigma', liq_mv_name, 'gam_n'] + fact_exp.columns.tolist()

        ref_data_com = reg_data[reg_data['gam_n'] == 1]

        # åŠ æƒï¼ˆæµé€šå¸‚å€¼ï¼‰æœ€å°äºŒä¹˜æ³•ç”¨ä¼˜è´¨è‚¡ç¥¨ä¼°è®¡å› å­å¯¹ç‰¹å¼‚æ³¢åŠ¨çš„è´¡çŒ®å€¼
        model = sm.WLS(ref_data_com['sigma'], ref_data_com[fact_exp.columns], weights=ref_data_com['gam_n']).fit()

        # ä¸ªè‚¡ç»“æž„åŒ–ç‰¹å¼‚æ³¢åŠ¨é¢„æµ‹å€¼
        sigma_STR = pd.DataFrame(np.diag(np.exp(np.dot(fact_exp, model.params)) * 1.05),
                                 index=fact_exp.index,
                                 columns=fact_exp.index)

        # å¯¹ç‰¹å¼‚æ”¶ç›ŠçŸ©é˜µè¿›è¡Œç»“æž„åŒ–è°ƒæ•´
        F_STR = sigma_STR.mul((1 - gam_n), axis=0) + cov.mul(gam_n, axis=0)

        return F_STR

    # è´å¶æ–¯åŽ‹ç¼©
    def Bayesian_compression(self,
                             cov: pd.DataFrame,
                             liq_mv: pd.DataFrame,
                             liq_mv_name: PVN.LIQ_MV.value,
                             group_num: int = 10,
                             q: int = 1
                             ):
        """
        ðœŽ_ð‘›_ð‘†ð» = ð‘£_ð‘›*ðœŽ_ð‘› + (1 âˆ’ ð‘£_ð‘›)*ðœŽ_ð‘›^

        :param cov: ç»ç»“æž„åŒ–è°ƒæ•´çš„ç‰¹å¼‚æ”¶ç›ŠçŸ©é˜µ
        :param liq_mv: æµé€šå¸‚å€¼
        :param liq_mv_name: æµé€šå¸‚å€¼åç§°
        :param group_num: åˆ†ç»„ä¸ªæ•°
        :param q: åŽ‹ç¼©ç³»æ•°ï¼Œè¯¥ç³»æ•°è¶Šå¤§ï¼Œå…ˆéªŒé£Žé™©çŸ©é˜µæ‰€å æƒé‡è¶Šå¤§
        :return:
        """
        df_ = pd.DataFrame({"sigma_n": np.diag(cov), liq_mv_name: liq_mv})
        # æŒ‰æµé€šå¸‚å€¼åˆ†ç»„
        df_['Group'] = pd.cut(df_['sigma_n'], group_num, labels=[f'Group_{i}' for i in range(1, group_num + 1)])

        # å„ç»„ç‰¹å¼‚é£Žé™©å¸‚å€¼åŠ æƒå‡å€¼
        df_['weight'] = df_.groupby('Group', group_keys=False).apply(lambda x: x[liq_mv_name] / x[liq_mv_name].sum())
        sigma_n_weight = df_.groupby('Group').apply(lambda x: x['weight'] @ x['sigma_n'])
        sigma_n_weight.name = 'sigma_n_weight'

        df_N1 = pd.merge(df_, sigma_n_weight, left_on=['Group'], right_index=True, how='left')

        # ä¸ªè‚¡æ‰€å±žåˆ†ç»„ç‰¹å¼‚æ³¢åŠ¨çš„æ ‡å‡†å·®

        try:
            delta_n = df_N1.groupby('Group').apply(
                lambda x: np.nan if x.empty else pow(sum((x['sigma_n'] - x['sigma_n_weight']) ** 2) / x.shape[0], 0.5))
        except Exception as e:
            delta_n = df_N1.groupby('Group').apply(
                lambda x: np.nan if x.empty else pow(sum((x['sigma_n'] - x['sigma_n_weight']) ** 2) / x.shape[0], 0.5))
            print(e)

        delta_n.name = 'delta'

        df_N2 = pd.merge(df_N1, delta_n, left_on=['Group'], right_index=True, how='left')

        # åŽ‹ç¼©ç³»æ•°
        df_N2['V_n'] = q * abs(df_N2['sigma_n'] - df_N2['sigma_n_weight']) / (df_N2['delta'] + q * abs(df_N2['sigma_n'] - df_N2['sigma_n_weight']))

        # è°ƒæ•´åŽçš„ç‰¹å¼‚æ³¢åŠ¨
        sigma_SH = df_N2['V_n'] * df_N2['sigma_n_weight'] + (1 - df_N2['V_n']) * df_N2['sigma_n']
        F_SH = pd.DataFrame(np.diag(np.array(sigma_SH)), index=sigma_SH.index, columns=sigma_SH.index)

        return F_SH

    # åŠè¡°æƒé‡
    @staticmethod
    def Half_time(period: int, decay: int = 2) -> list:

        weight_list = [pow(2, (i - period - 1) / decay) for i in range(1, period + 1)]

        weight_1 = [i / sum(weight_list) for i in weight_list]

        return weight_1
